<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>FCConDubber</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#157878">
    <link rel="stylesheet" href="css/normalize.css">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" href="css/cayman.css">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name" style="font-size: 3.0rem;">FCConDubber</h1>
      <h1 class="project-name">Fine And Coarse Grained Prosody Alignment For Expressive Video Dubbing via
        Contrastive Speech-Motion
        Pretraining</h1>
      <a href="#" class="btn">Paper</a>
      <a href="#" class="btn">Project</a>
      <!-- <a href="#" class="btn">Download .zip</a>
      <a href="#" class="btn">Download .tar.gz</a> -->
    </section>



    <section class="main-content">
      <h1 id="abstract">Abstract</h1>
      <!-- <p>Text-to-Speech (TTS) system based on deep learning has witnessed significant progress. The naturalness and similarity of speech synthesized by the general TTS systems are close to human speech. Research on zero-shot TTS has become a more challenging speech generation task, but current models lack flexible control over emotional information. This paper proposes a controllable emotional TTS Zero-Shot  system based on multi-modal prompt, MPE-TTS, which allows prompts of both natural language description and reference speech to control the emotion of synthesized speech. Firstly, we introduce the pretrained Emotion2Vec as the emotion feature extractor and construct a multi-modal emotion dataset for training. Then,we propose a multi-modal emotion encoder to extract the emotion information from the prompts. Finally, we introduce a prosody predictor module based on an autoregressive transformer to predict the prosody and use a diffusion-based acoustic model to synthesize speech. The subjective and objective experiments show that the proposed model achieves flexible emotional control while ensuring the naturalness of synthesized speech, expanding the application scenarios of TTS systems. Besides, this method can be easily extended to other TTS systems.</p> -->
      <p>Automatic Video Dubbing (AVD) aims to synthesize speech that matches a character’s speaking style and emotion in silent
      video clips. However, existing approaches rely on attention mechanisms to learn cross-modal prosodic alignment
      implicitly, making it challenging to capture subtle prosodic variations and impacting the overall naturalness and
      expressiveness of the output. In this paper, we propose FCConDubber, a novel dubbing model that generates high-fidelity
      and expressive speech by utilizing a pre-trained prosodic alignment framework. The model incorporates a contrastive
      speech-motion pre-training framework to learn fine-grained temporal prosodic alignment and coarse-grained global style
      information. Experiments on the MEAD dataset demonstrate that FCConDubber significantly outperforms baseline models in
      speech synthesis quality and prosody reconstruction, successfully capturing and reproducing the speaker’s prosodic
      characteristics in the video.</p>

      <h2 id="speech-based-emotion-control">Proposed Method</h2>
      <p>Figure 1 illustrates the primary architecture of the proposed model, which consists of four modules. 
        <ol>
          <li><strong>Contrastive Speech-Motion Pretraining(CSMP)</strong> a multi-grained prosodic alignment framework based on contrastive learning. It
          incorporates a speech prosody encoder and a visual prosody encoder to extract prosodic feature representations from
          speech and facial movements respectively. CSMP then employs contrastive learning to align the speech prosody and facial
          motion information.</li>
          <li>Acoustic Model: converting textual semantic information into corresponding mel spectrograms.</li>
          <li>A mel-spectrogram refiner based on rectified flow, which makes the generated mel spectrogram closer to the ground truth.</li>
          <li>A vocoder that transforms the mel spectrogram into audio waveforms.</li>
        </ol> 
      </p>
        <!-- 1) Contrastive Speech-Motion Pretraining(CSMP): a multi-grained prosodic alignment framework based on contrastive learning. It -->
      <!-- incorporates a speech prosody encoder and a visual prosody encoder to extract prosodic feature representations from -->
      <!-- speech and facial movements respectively. CSMP then employs contrastive learning to align the speech prosody and facial -->
      <!-- motion information. 2) MelSpectrogram Generator: converting textual semantic information into corresponding mel -->
      <!-- spectrograms. 3) A mel-spectrogram refiner based on rectified flow, which makes the generated mel spectrogram closer to -->
      <!-- the ground truth. 4) A vocoder that transforms the mel spectrogram into audio waveforms. </p> -->
      
      <img src="./assets/model.png" alt="Figure 1" style="width: 100%; height: auto;">

      <!-- <h4 id="note">( Note that: in the 'Ours w/o MPEE', we replaced the proposed MPEE  with the AMPE of MM-TTS ) </h4> -->
      <h2>Comparisons</h2>
      <table>
        <thead>
          <tr>
            <th><center> Grount truth </center></th>
            <th><center> Reconstruction </center></th>
            <th><center> Nerual Dubber </center></th>
            <th><center> 3D-VD </center></th>
            <th><center> Ours </center></th>
          </tr>
        </thead>

        <tbody>
          <tr>
            <td><audio src="samples/gt/0.wav" controls="" preload=""></audio></td>
            <td><audio src="samples/reconstruction/0.wav" controls="" preload=""></audio></td>
            <td><audio src="samples/nerual_dubber/0.wav" controls="" preload=""></audio></td>
            <td><audio src="samples/3d_vd/0.wav" controls="" preload=""></audio></td>
            <td><audio src="samples/ours/0.wav" controls="" preload=""></audio></td>
          </tr>
          <!-- 剩下9个 -->
          <tr>
            <td><audio src="samples/gt/1.wav" controls="" preload=""></audio></td>
            <td><audio src="samples/reconstruction/1.wav" controls="" preload=""></audio></td>
            <td><audio src="samples/nerual_dubber/1.wav" controls="" preload=""></audio></td>
            <td><audio src="samples/3d_vd/1.wav" controls="" preload=""></audio></td>
            <td><audio src="samples/ours/1.wav" controls="" preload=""></audio></td>
          </tr>
          <tr>
            <td><audio src="samples/gt/2.wav" controls="" preload=""></audio></td>
            <td><audio src="samples/reconstruction/2.wav" controls="" preload=""></audio></td>
            <td><audio src="samples/nerual_dubber/2.wav" controls="" preload=""></audio></td>
            <td><audio src="samples/3d_vd/2.wav" controls="" preload=""></audio></td>
            <td><audio src="samples/ours/2.wav" controls="" preload=""></audio></td>
          </tr>
          <tr>
            <td><audio src="samples/gt/3.wav" controls="" preload=""></audio></td>
            <td><audio src="samples/reconstruction/3.wav" controls="" preload=""></audio></td>
            <td><audio src="samples/nerual_dubber/3.wav" controls="" preload=""></audio></td>
            <td><audio src="samples/3d_vd/3.wav" controls="" preload=""></audio></td>
            <td><audio src="samples/ours/3.wav" controls="" preload=""></audio></td>
          </tr>
          <tr>
            <td><audio src="samples/gt/4.wav" controls="" preload=""></audio></td>
            <td><audio src="samples/reconstruction/4.wav" controls="" preload=""></audio></td>
            <td><audio src="samples/nerual_dubber/4.wav" controls="" preload=""></audio></td>
            <td><audio src="samples/3d_vd/4.wav" controls="" preload=""></audio></td>
            <td><audio src="samples/ours/4.wav" controls="" preload=""></audio></td>
          </tr>
          <tr>
            <td><audio src="samples/gt/5.wav" controls="" preload=""></audio></td>
            <td><audio src="samples/reconstruction/5.wav" controls="" preload=""></audio></td>
            <td><audio src="samples/nerual_dubber/5.wav" controls="" preload=""></audio></td>
            <td><audio src="samples/3d_vd/5.wav" controls="" preload=""></audio></td>
            <td><audio src="samples/ours/5.wav" controls="" preload=""></audio></td>
          </tr>
          <tr>
            <td><audio src="samples/gt/6.wav" controls="" preload=""></audio></td>
            <td><audio src="samples/reconstruction/6.wav" controls="" preload=""></audio></td>
            <td><audio src="samples/nerual_dubber/6.wav" controls="" preload=""></audio></td>
            <td><audio src="samples/3d_vd/6.wav" controls="" preload=""></audio></td>
            <td><audio src="samples/ours/6.wav" controls="" preload=""></audio></td>
          </tr>
          <tr>
            <td><audio src="samples/gt/7.wav" controls="" preload=""></audio></td>
            <td><audio src="samples/reconstruction/7.wav" controls="" preload=""></audio></td>
            <td><audio src="samples/nerual_dubber/7.wav" controls="" preload=""></audio></td>
            <td><audio src="samples/3d_vd/7.wav" controls="" preload=""></audio></td>
            <td><audio src="samples/ours/7.wav" controls="" preload=""></audio></td>
          </tr>
          <tr>
            <td><audio src="samples/gt/8.wav" controls="" preload=""></audio></td>
            <td><audio src="samples/reconstruction/8.wav" controls="" preload=""></audio></td>
            <td><audio src="samples/nerual_dubber/8.wav" controls="" preload=""></audio></td>
            <td><audio src="samples/3d_vd/8.wav" controls="" preload=""></audio></td>
            <td><audio src="samples/ours/8.wav" controls="" preload=""></audio></td>
          </tr>
          <tr>
            <td><audio src="samples/gt/9.wav" controls="" preload=""></audio></td>
            <td><audio src="samples/reconstruction/9.wav" controls="" preload=""></audio></td>
            <td><audio src="samples/nerual_dubber/9.wav" controls="" preload=""></audio></td>
            <td><audio src="samples/3d_vd/9.wav" controls="" preload=""></audio></td>
            <td><audio src="samples/ours/9.wav" controls="" preload=""></audio></td>
          </tr>
        </tbody>
      </table>

      

      <footer class="site-footer">
        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a>.</span>
      </footer>

    </section>

  </body>
</html>